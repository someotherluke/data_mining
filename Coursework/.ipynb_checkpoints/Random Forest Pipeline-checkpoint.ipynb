{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\lodke\\anaconda3\\lib\\site-packages (2.6.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from category_encoders) (6.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from category_encoders) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from category_encoders) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from category_encoders) (1.5.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from category_encoders) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from category_encoders) (1.19.2)\n",
      "Requirement already satisfied: six in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->category_encoders) (3.4.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\lodke\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lodke\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "#dataframe handling\n",
    "import pandas as pd\n",
    "#mathematics\n",
    "import numpy as np\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#encoding\n",
    "!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#What it says on the tin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#outlier detection\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "#imputer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "#clustering checkers\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "#feature selection\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#upsampling\n",
    "!pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#scaling \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set-up\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data\n",
    "disease_train     = pd.read_csv('disease_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove obvious age outliers\n",
    "disease_train_agesremoved = disease_train[(disease_train['age'] != 65526) & (disease_train['age'] != 455)] \n",
    "\n",
    "#Drop axes that aren't helpful\n",
    "disease_clean = disease_train_agesremoved.drop('test_X6', axis=1)\n",
    "disease_clean = disease_clean.drop('id', axis=1)\n",
    "\n",
    "#Differentiate null entries in gender from null entries in other variables\n",
    "disease_clean['gender'] = disease_clean['gender'].fillna('empty')\n",
    "\n",
    "#Reset index to account for dropped rows\n",
    "disease_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "disease_clean_v0 = disease_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split lists for tests/modules that require only one\n",
    "\n",
    "#Categorical\n",
    "disease_cat = ['sick',            'pregnant',      'concern_type1',   'concern_type2',\n",
    "                'enlargement',     'tumor'   ,      'disorder',        'medication_A',\n",
    "                'medication_B',    'mental_health', 'mood_stabiliser', 'surgery',\n",
    "                'treatment_type1', 'suspect', 'gender', 'target']\n",
    "\n",
    "#Numerical\n",
    "disease_num  = ['age', 'test_X1', 'test_X2', 'test_X3', 'test_X4', 'test_X5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal\n",
    "disease_clean_v1 = disease_clean.dropna()\n",
    "\n",
    "#Imputation - Using the median since our data is skewed (knn tried for other algorithms)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(disease_clean[disease_num])\n",
    "\n",
    "#Produce array with imputed values\n",
    "disease_temp = imputer.transform(disease_clean[disease_num])\n",
    "\n",
    "#Turn array back into a data frame\n",
    "disease_temp_df = pd.DataFrame(disease_temp, columns=disease_num)\n",
    "\n",
    "#Create a copy of our clean dataframe\n",
    "disease_clean_v2 = disease_clean.copy()\n",
    "\n",
    "#Give the copy the imputed columns\n",
    "disease_clean_v2[disease_num] = disease_temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two sets of selected for features from data analysis\n",
    "disease_input = [\n",
    "                 'test_X1',       'test_X5',  'test_X3', 'test_X2',      'test_X4',\n",
    "                 'concern_type2', 'suspect',  'age',     'medication_A', 'medication_B',\n",
    "                 'gender',\n",
    "                ]\n",
    "\n",
    "disease_input_strict = [                 \n",
    "                         'test_X1', 'test_X5', 'test_X3', 'test_X2', 'test_X4',\n",
    "                        ]\n",
    "\n",
    "disease_output = ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disease_clean_v2\n",
    "#disease_clean_v1\n",
    "#disease_clean_v0\n",
    "\n",
    "disease_clean_v0_inp    = disease_clean_v0[disease_input].copy()\n",
    "disease_clean_v0_inpstr = disease_clean_v0[disease_input_strict].copy()\n",
    "disease_clean_v0_out    = disease_clean_v0[disease_output].copy()\n",
    "\n",
    "disease_clean_v1_inp    = disease_clean_v1[disease_input].copy()\n",
    "disease_clean_v1_inpstr = disease_clean_v1[disease_input_strict].copy()\n",
    "disease_clean_v1_out    = disease_clean_v1[disease_output].copy()\n",
    "\n",
    "disease_clean_v2_inp    = disease_clean_v2[disease_input].copy()\n",
    "disease_clean_v2_inpstr = disease_clean_v2[disease_input_strict].copy()\n",
    "disease_clean_v2_out    = disease_clean_v2[disease_output].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholders for null values\n",
    "disease_clean_v0_inp    = disease_clean_v0_inp.fillna(-999)\n",
    "disease_clean_v0_inpstr = disease_clean_v0_inpstr.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (2548, 11) (2548, 1)\n",
      "Validation set shape:  (850, 11) (850, 1)\n",
      "Test set shape:  (850, 11) (850, 1)\n"
     ]
    }
   ],
   "source": [
    "#The train test split\n",
    "X_temp_v0_all, X_test_v0_all, y_temp_v0_all, y_test_v0_all = train_test_split(\n",
    "    disease_clean_v0_inp, disease_clean_v0_out, test_size=0.2, random_state=42, stratify=disease_clean_v0_out\n",
    ")\n",
    "\n",
    "#The train validation split (0.25 since this will make validation and test the same size)\n",
    "X_train_v0_all, X_val_v0_all, y_train_v0_all, y_val_v0_all = train_test_split(\n",
    "    X_temp_v0_all, y_temp_v0_all, test_size=0.25, random_state=42, stratify=y_temp_v0_all\n",
    ")\n",
    "\n",
    "# Check the shapes of the resulting splits to ensure correctness\n",
    "print('Training set shape: ',X_train_v0_all.shape, y_train_v0_all.shape)\n",
    "print('Validation set shape: ',X_val_v0_all.shape, y_val_v0_all.shape)\n",
    "print('Test set shape: ',X_test_v0_all.shape, y_test_v0_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (2548, 5) (2548, 1)\n",
      "Validation set shape:  (850, 5) (850, 1)\n",
      "Test set shape:  (850, 5) (850, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_X1</th>\n",
       "      <th>test_X5</th>\n",
       "      <th>test_X3</th>\n",
       "      <th>test_X2</th>\n",
       "      <th>test_X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>0.85</td>\n",
       "      <td>125.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1.00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>2.30</td>\n",
       "      <td>76.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>0.02</td>\n",
       "      <td>148.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_X1  test_X5  test_X3  test_X2  test_X4\n",
       "1836  -999.00   -999.0   -999.0   -999.0  -999.00\n",
       "1399     0.85    125.0    141.0      2.3     1.14\n",
       "1541     1.00     83.0     79.0      1.7     0.95\n",
       "3865     2.30     76.0     78.0      1.8     1.04\n",
       "2466     0.02    148.0    136.0      2.4     0.92"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The train test split\n",
    "X_temp_v0_str, X_test_v0_str, y_temp_v0_str, y_test_v0_str = train_test_split(\n",
    "    disease_clean_v0_inpstr, disease_clean_v0_out, test_size=0.2, random_state=42, stratify=disease_clean_v0_out\n",
    ")\n",
    "\n",
    "#The train validation split (0.25 since this will make validation and test the same size)\n",
    "X_train_v0_str, X_val_v0_str, y_train_v0_str, y_val_v0_str = train_test_split(\n",
    "    X_temp_v0_str, y_temp_v0_str, test_size=0.25, random_state=42, stratify=y_temp_v0_str\n",
    ")\n",
    "\n",
    "# Check the shapes of the resulting splits to ensure correctness\n",
    "print('Training set shape: ',X_train_v0_str.shape, y_train_v0_str.shape)\n",
    "print('Validation set shape: ',X_val_v0_str.shape, y_val_v0_str.shape)\n",
    "print('Test set shape: ',X_test_v0_str.shape, y_test_v0_str.shape)\n",
    "\n",
    "#X_train_v0_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_X1</th>\n",
       "      <th>test_X5</th>\n",
       "      <th>test_X3</th>\n",
       "      <th>test_X2</th>\n",
       "      <th>test_X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>0.85</td>\n",
       "      <td>125.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1.00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>2.30</td>\n",
       "      <td>76.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>0.02</td>\n",
       "      <td>148.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_X1  test_X5  test_X3  test_X2  test_X4\n",
       "1836      NaN      NaN      NaN      NaN      NaN\n",
       "1399     0.85    125.0    141.0      2.3     1.14\n",
       "1541     1.00     83.0     79.0      1.7     0.95\n",
       "3865     2.30     76.0     78.0      1.8     1.04\n",
       "2466     0.02    148.0    136.0      2.4     0.92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reset placeholder\n",
    "X_train_v0_all = X_train_v0_all.replace(-999, np.nan)\n",
    "X_val_v0_all   = X_val_v0_all.replace(-999, np.nan)\n",
    "\n",
    "X_train_v0_str = X_train_v0_str.replace(-999, np.nan)\n",
    "X_val_v0_str   = X_val_v0_str.replace(-999, np.nan)\n",
    "\n",
    "#X_train_v0_str.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (1627, 11) (1627, 1)\n",
      "Validation set shape:  (543, 11) (543, 1)\n",
      "Test set shape:  (543, 11) (543, 1)\n"
     ]
    }
   ],
   "source": [
    "#The train test split\n",
    "X_temp_v1_all, X_test_v1_all, y_temp_v1_all, y_test_v1_all = train_test_split(\n",
    "    disease_clean_v1_inp, disease_clean_v1_out, test_size=0.2, random_state=42, stratify=disease_clean_v1_out\n",
    ")\n",
    "\n",
    "#The train validation split (0.25 since this will make validation and test the same size)\n",
    "X_train_v1_all, X_val_v1_all, y_train_v1_all, y_val_v1_all = train_test_split(\n",
    "    X_temp_v1_all, y_temp_v1_all, test_size=0.25, random_state=42, stratify=y_temp_v1_all\n",
    ")\n",
    "\n",
    "# Check the shapes of the resulting splits to ensure correctness\n",
    "print('Training set shape: ',X_train_v1_all.shape, y_train_v1_all.shape)\n",
    "print('Validation set shape: ',X_val_v1_all.shape, y_val_v1_all.shape)\n",
    "print('Test set shape: ',X_test_v1_all.shape, y_test_v1_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (1627, 11) (1627, 1)\n",
      "Validation set shape:  (543, 11) (543, 1)\n",
      "Test set shape:  (543, 11) (543, 1)\n"
     ]
    }
   ],
   "source": [
    "#The train test split\n",
    "X_temp_v1_all, X_test_v1_all, y_temp_v1_all, y_test_v1_all = train_test_split(\n",
    "    disease_clean_v1_inp, disease_clean_v1_out, test_size=0.2, random_state=42, stratify=disease_clean_v1_out\n",
    ")\n",
    "\n",
    "#The train validation split (0.25 since this will make validation and test the same size)\n",
    "X_train_v1_all, X_val_v1_all, y_train_v1_all, y_val_v1_all = train_test_split(\n",
    "    X_temp_v1_all, y_temp_v1_all, test_size=0.25, random_state=42, stratify=y_temp_v1_all\n",
    ")\n",
    "\n",
    "# Check the shapes of the resulting splits to ensure correctness\n",
    "print('Training set shape: ',X_train_v1_all.shape, y_train_v1_all.shape)\n",
    "print('Validation set shape: ',X_val_v1_all.shape, y_val_v1_all.shape)\n",
    "print('Test set shape: ',X_test_v1_all.shape, y_test_v1_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (2548, 11) (2548, 1)\n",
      "Validation set shape:  (850, 11) (850, 1)\n",
      "Test set shape:  (850, 11) (850, 1)\n"
     ]
    }
   ],
   "source": [
    "#The train test split\n",
    "X_temp_v2_all, X_test_v2_all, y_temp_v2_all, y_test_v2_all = train_test_split(\n",
    "    disease_clean_v2_inp, disease_clean_v2_out, test_size=0.2, random_state=42, stratify=disease_clean_v2_out\n",
    ")\n",
    "\n",
    "#The train validation split (0.25 since this will make validation and test the same size)\n",
    "X_train_v2_all, X_val_v2_all, y_train_v2_all, y_val_v2_all = train_test_split(\n",
    "    X_temp_v2_all, y_temp_v2_all, test_size=0.25, random_state=42, stratify=y_temp_v2_all\n",
    ")\n",
    "\n",
    "# Check the shapes of the resulting splits to ensure correctness\n",
    "print('Training set shape: ',X_train_v2_all.shape, y_train_v2_all.shape)\n",
    "print('Validation set shape: ',X_val_v2_all.shape, y_val_v2_all.shape)\n",
    "print('Test set shape: ',X_test_v2_all.shape, y_test_v2_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (2548, 11) (2548, 1)\n",
      "Validation set shape:  (850, 11) (850, 1)\n",
      "Test set shape:  (850, 11) (850, 1)\n"
     ]
    }
   ],
   "source": [
    "#The train test split\n",
    "X_temp_v2_all, X_test_v2_all, y_temp_v2_all, y_test_v2_all = train_test_split(\n",
    "    disease_clean_v2_inp, disease_clean_v2_out, test_size=0.2, random_state=42, stratify=disease_clean_v2_out\n",
    ")\n",
    "\n",
    "#The train validation split (0.25 since this will make validation and test the same size)\n",
    "X_train_v2_all, X_val_v2_all, y_train_v2_all, y_val_v2_all = train_test_split(\n",
    "    X_temp_v2_all, y_temp_v2_all, test_size=0.25, random_state=42, stratify=y_temp_v2_all\n",
    ")\n",
    "\n",
    "# Check the shapes of the resulting splits to ensure correctness\n",
    "print('Training set shape: ',X_train_v2_all.shape, y_train_v2_all.shape)\n",
    "print('Validation set shape: ',X_val_v2_all.shape, y_val_v2_all.shape)\n",
    "print('Test set shape: ',X_test_v2_all.shape, y_test_v2_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_X1</th>\n",
       "      <th>test_X5</th>\n",
       "      <th>test_X3</th>\n",
       "      <th>test_X2</th>\n",
       "      <th>test_X4</th>\n",
       "      <th>concern_type2</th>\n",
       "      <th>suspect</th>\n",
       "      <th>age</th>\n",
       "      <th>medication_A</th>\n",
       "      <th>medication_B</th>\n",
       "      <th>G_empty</th>\n",
       "      <th>G_female</th>\n",
       "      <th>G_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>94.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>121.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.10</td>\n",
       "      <td>111.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>79.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_X1  test_X5  test_X3  test_X2  test_X4  concern_type2  suspect  age  \\\n",
       "0     1.60     74.0     87.0      2.2     1.17            1.0      1.0   72   \n",
       "1     0.95     94.0    109.0      2.0     1.15            1.0      1.0   68   \n",
       "2     0.15    121.0     92.0      2.2     0.76            1.0      1.0   57   \n",
       "3     2.10    111.0     80.0      1.8     0.72            1.0      1.0   78   \n",
       "4     0.04     79.0     61.0      1.0     0.77            1.0      1.0   39   \n",
       "\n",
       "   medication_A  medication_B  G_empty  G_female  G_male  \n",
       "0           1.0           1.0      0.0       0.0     1.0  \n",
       "1           1.0           1.0      0.0       1.0     0.0  \n",
       "2           1.0           1.0      0.0       1.0     0.0  \n",
       "3           1.0           1.0      0.0       0.0     1.0  \n",
       "4           1.0           1.0      0.0       0.0     1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_v1_all.head()\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#passing gender columns\n",
    "enc_gender = pd.DataFrame(enc.fit_transform(X_train_v1_all[['gender']]).toarray())\n",
    "enc_gender.columns = ['G_empty', 'G_female', 'G_male']\n",
    "\n",
    "#We need to do this so that when we concatonate we don't get an index issue and introduce null values and 2 extraineous rows\n",
    "X_train_v1_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train_v1_all_encd= pd.concat([X_train_v1_all, enc_gender], axis=1)\n",
    "#print(encode2_disease.shape)\n",
    "\n",
    "#Remove the original gender column\n",
    "X_train_v1_all_encd = X_train_v1_all_encd.drop('gender', axis=1)\n",
    "\n",
    "#X_train_v1_all_encd.head()\n",
    "\n",
    "#Booleans encoding\n",
    "temp_bool = ['concern_type2','suspect','medication_A','medication_B']\n",
    "\n",
    "enc = ce.OrdinalEncoder(cols=temp_bool, handle_missing='return_nan',return_df= True)\n",
    "\n",
    "X_train_v1_all_encd=enc.fit_transform(X_train_v1_all_encd)\n",
    "\n",
    "X_train_v1_all_encd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LODKe\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:307: UserWarning: max_samples (31258) is greater than the total number of samples (1627). max_samples will be set to n_samples for estimation.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outliers identified is:  17\n",
      "(1610, 1)\n",
      "(1610, 13)\n"
     ]
    }
   ],
   "source": [
    "#Use the algorithm for outlier detection, then use it to predict each point\n",
    "#Any point labelled as -1 is an outlier\n",
    "clf = IsolationForest(max_samples=31258, random_state = 404,contamination= 0.01)\n",
    "preds = clf.fit_predict(X_train_v1_all_encd)\n",
    "#print(preds)\n",
    "totalOutliers=0\n",
    "for pred in preds:\n",
    "    if pred == -1:\n",
    "        totalOutliers=totalOutliers+1\n",
    "print(\"Total number of outliers identified is: \",totalOutliers)\n",
    "\n",
    "# select all rows that are not outliers and create a boolean mask\n",
    "mask = preds != -1\n",
    "# Apply mask to y and check shape\n",
    "y2= y_train_v1_all[mask]\n",
    "print (y2.shape)\n",
    "\n",
    "#Apply mask to X and check shape \n",
    "X2=X_train_v1_all_encd[mask]\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_X1</th>\n",
       "      <th>test_X5</th>\n",
       "      <th>test_X3</th>\n",
       "      <th>test_X2</th>\n",
       "      <th>test_X4</th>\n",
       "      <th>concern_type2</th>\n",
       "      <th>suspect</th>\n",
       "      <th>age</th>\n",
       "      <th>medication_A</th>\n",
       "      <th>medication_B</th>\n",
       "      <th>G_empty</th>\n",
       "      <th>G_female</th>\n",
       "      <th>G_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>94.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>121.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.10</td>\n",
       "      <td>111.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>79.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_X1  test_X5  test_X3  test_X2  test_X4  concern_type2  suspect  age  \\\n",
       "0     1.60     74.0     87.0      2.2     1.17            1.0      1.0   72   \n",
       "1     0.95     94.0    109.0      2.0     1.15            1.0      1.0   68   \n",
       "2     0.15    121.0     92.0      2.2     0.76            1.0      1.0   57   \n",
       "3     2.10    111.0     80.0      1.8     0.72            1.0      1.0   78   \n",
       "4     0.04     79.0     61.0      1.0     0.77            1.0      1.0   39   \n",
       "\n",
       "   medication_A  medication_B  G_empty  G_female  G_male  \n",
       "0           1.0           1.0      0.0       0.0     1.0  \n",
       "1           1.0           1.0      0.0       1.0     0.0  \n",
       "2           1.0           1.0      0.0       1.0     0.0  \n",
       "3           1.0           1.0      0.0       0.0     1.0  \n",
       "4           1.0           1.0      0.0       0.0     1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2[temp_bool] = X2[temp_bool].copy() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for bol in temp_bool:\n",
    "    X2_unique = X2[bol].unique()\n",
    "    print(X2_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "       test_X1   test_X5   test_X3   test_X2   test_X4  concern_type2  \\\n",
      "0     0.003009  0.204738  0.284281  0.284768  0.613333            0.0   \n",
      "1     0.001783  0.261139  0.357860  0.258278  0.600000            0.0   \n",
      "2     0.000274  0.337281  0.301003  0.284768  0.340000            0.0   \n",
      "3     0.003953  0.309081  0.260870  0.231788  0.313333            0.0   \n",
      "4     0.000066  0.218838  0.197324  0.125828  0.346667            0.0   \n",
      "...        ...       ...       ...       ...       ...            ...   \n",
      "1622  0.003387  0.266779  0.334448  0.205298  0.546667            0.0   \n",
      "1623  0.000387  0.385223  0.468227  0.258278  0.520000            0.0   \n",
      "1624  0.002821  0.311901  0.371237  0.231788  0.506667            1.0   \n",
      "1625  0.003953  0.396503  0.441472  0.324503  0.460000            0.0   \n",
      "1626  0.332069  0.007332  0.013378  0.059603  0.800000            0.0   \n",
      "\n",
      "      suspect       age  medication_A  medication_B  G_empty  G_female  G_male  \n",
      "0         0.0  0.736842           0.0           0.0      0.0       0.0     1.0  \n",
      "1         0.0  0.694737           0.0           0.0      0.0       1.0     0.0  \n",
      "2         0.0  0.578947           0.0           0.0      0.0       1.0     0.0  \n",
      "3         0.0  0.800000           0.0           0.0      0.0       0.0     1.0  \n",
      "4         0.0  0.389474           0.0           0.0      0.0       0.0     1.0  \n",
      "...       ...       ...           ...           ...      ...       ...     ...  \n",
      "1622      0.0  0.589474           0.0           0.0      0.0       0.0     1.0  \n",
      "1623      0.0  0.589474           0.0           0.0      0.0       1.0     0.0  \n",
      "1624      0.0  0.621053           0.0           0.0      0.0       1.0     0.0  \n",
      "1625      0.0  0.578947           0.0           0.0      0.0       1.0     0.0  \n",
      "1626      0.0  0.473684           0.0           0.0      0.0       0.0     1.0  \n",
      "\n",
      "[1610 rows x 13 columns]\n",
      "\n",
      "Scaled Data:\n",
      "       test_X1   test_X5   test_X3   test_X2   test_X4  concern_type2  \\\n",
      "0     0.003009  0.204738  0.284281  0.284768  0.613333            0.0   \n",
      "1     0.001783  0.261139  0.357860  0.258278  0.600000            0.0   \n",
      "2     0.000274  0.337281  0.301003  0.284768  0.340000            0.0   \n",
      "3     0.003953  0.309081  0.260870  0.231788  0.313333            0.0   \n",
      "4     0.000066  0.218838  0.197324  0.125828  0.346667            0.0   \n",
      "...        ...       ...       ...       ...       ...            ...   \n",
      "1622  0.003387  0.266779  0.334448  0.205298  0.546667            0.0   \n",
      "1623  0.000387  0.385223  0.468227  0.258278  0.520000            0.0   \n",
      "1624  0.002821  0.311901  0.371237  0.231788  0.506667            1.0   \n",
      "1625  0.003953  0.396503  0.441472  0.324503  0.460000            0.0   \n",
      "1626  0.332069  0.007332  0.013378  0.059603  0.800000            0.0   \n",
      "\n",
      "      suspect       age  medication_A  medication_B  G_empty  G_female  G_male  \n",
      "0         0.0  0.736842           0.0           0.0      0.0       0.0     1.0  \n",
      "1         0.0  0.694737           0.0           0.0      0.0       1.0     0.0  \n",
      "2         0.0  0.578947           0.0           0.0      0.0       1.0     0.0  \n",
      "3         0.0  0.800000           0.0           0.0      0.0       0.0     1.0  \n",
      "4         0.0  0.389474           0.0           0.0      0.0       0.0     1.0  \n",
      "...       ...       ...           ...           ...      ...       ...     ...  \n",
      "1622      0.0  0.589474           0.0           0.0      0.0       0.0     1.0  \n",
      "1623      0.0  0.589474           0.0           0.0      0.0       1.0     0.0  \n",
      "1624      0.0  0.621053           0.0           0.0      0.0       1.0     0.0  \n",
      "1625      0.0  0.578947           0.0           0.0      0.0       1.0     0.0  \n",
      "1626      0.0  0.473684           0.0           0.0      0.0       0.0     1.0  \n",
      "\n",
      "[1610 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-85e7fd920d4c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X2[cols_scaled] = scaler.fit_transform(X2[cols_scaled])\n",
      "C:\\Users\\LODKe\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3072: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.iloc._setitem_with_indexer((slice(None), indexer), value)\n",
      "C:\\Users\\LODKe\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3037: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "#Picking a scaler this one just uses min/max to scale values between [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(X2)\n",
    "\n",
    "cols_scaled = ['test_X1','test_X5','test_X3','test_X2','test_X4','age']\n",
    "\n",
    "X2[cols_scaled] = scaler.fit_transform(X2[cols_scaled])\n",
    "\n",
    "print(\"\\nScaled Data:\")\n",
    "print(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_risk         1371\n",
      "moderate_risk     187\n",
      "high_risk          52\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x= 'target', palette='colorblind', data=y2)\n",
    "\n",
    "print(y2['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_risk = y2[y2['target'] == 'low_risk']\n",
    "moderate_risk = y2[y2['target'] == 'moderate_risk']\n",
    "high_risk = y2[y2['target'] == 'high_risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_risk_downsampled = resample(low_risk, replace=False, n_samples=1000, random_state=404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_balanced = pd.concat([low_risk_downsampled, moderate_risk, high_risk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
