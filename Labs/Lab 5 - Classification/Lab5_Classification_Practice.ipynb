{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining CMP-7023B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: Supervised Learning - Classification Part 1 - practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keppler\n",
    "\n",
    "## Context\n",
    "\n",
    "The Kepler Space Observatory is a NASA-build satellite that was launched in 2009. The telescope is dedicated to searching for exoplanets in star systems besides our own, with the ultimate goal of possibly finding other habitable planets besides our own. The original mission ended in 2013 due to mechanical failures, but the telescope has nevertheless been functional since 2014 on a \"K2\" extended mission.\n",
    "\n",
    "Kepler had verified 1284 new exoplanets as of May 2016. As of October 2017 there are over 3000 confirmed exoplanets total (using all detection methods, including ground-based ones). The telescope is still active and continues to collect new data on its extended mission.\n",
    "## Content\n",
    "\n",
    "This dataset is a cumulative record of all observed Kepler \"objects of interest\" — basically, all of the approximately 10,000 exoplanet candidates Kepler has taken observations on.\n",
    "\n",
    "This dataset has an extensive data dictionary, which can be accessed here. Highlightable columns of note are:\n",
    "\n",
    "    kepoi_name: A KOI is a target identified by the Kepler Project that displays at least one transit-like sequence within Kepler time-series photometry that appears to be of astrophysical origin and initially consistent with a planetary transit hypothesis\n",
    "    kepler_name: [These names] are intended to clearly indicate a class of objects that have been confirmed or validated as planets—a step up from the planet candidate designation.\n",
    "    koi_disposition: The disposition in the literature towards this exoplanet candidate. One of CANDIDATE, FALSE POSITIVE, NOT DISPOSITIONED or CONFIRMED.\n",
    "    koi_pdisposition: The disposition Kepler data analysis has towards this exoplanet candidate. One of FALSE POSITIVE, NOT DISPOSITIONED, and CANDIDATE.\n",
    "    koi_score: A value between 0 and 1 that indicates the confidence in the KOI disposition. For CANDIDATEs, a higher value indicates more confidence in its disposition, while for FALSE POSITIVEs, a higher value indicates less confidence in that disposition.\n",
    "\n",
    "Acknowledgements\n",
    "\n",
    "This dataset was published as-is by NASA. You can access the original table here. More data from the Kepler mission is available from the same source here.\n",
    "\n",
    "https://www.kaggle.com/nasa/kepler-exoplanet-search-results\n",
    "\n",
    "link: https://github.com/OpenExoplanetCatalogue/open_exoplanet_catalogue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting out: loading data and libraries\n",
    "We begin by loading the necessary libraries for the work we are going to do in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#designate the path where you saved your OEC data\n",
    "planet_data_path = \"C:\\\\DM-DATA\\\\planets.csv\"\n",
    "\n",
    "#Load the data using pandas read_csv function. \n",
    "orig_data = pd.read_csv(planet_data_path)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what are the names of the columns we want to use.\n",
    "\n",
    "not using: `[\"rowid\",\"kepid\",\"kepoi_name\",\"kepler_name\",\"koi_pdisposition\",koi_tce_delivname\",\"koi_tce_delivname\"]`\n",
    "\n",
    "empty cols: `[\"koi_teq_err1\",\"koi_teq_err2\"]`\n",
    "\n",
    "The koi_disposition will be our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"koi_disposition\"\n",
    "label = orig_data[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [\"koi_score\",\"koi_fpflag_nt\",\"koi_fpflag_ss\",\"koi_fpflag_co\",\"koi_fpflag_ec\",\n",
    "                   \"koi_period\",\"koi_period_err1\",\"koi_period_err2\",\"koi_time0bk\",\"koi_time0bk_err1\",\n",
    "                   \"koi_time0bk_err2\",\"koi_impact\",\"koi_impact_err1\",\"koi_impact_err2\",\"koi_duration\",\n",
    "                   \"koi_duration_err1\",\"koi_duration_err2\",\"koi_depth\",\"koi_depth_err1\",\"koi_depth_err2\",\n",
    "                   \"koi_prad\",\"koi_prad_err1\",\"koi_prad_err2\",\"koi_teq\",\"koi_insol\",\"koi_insol_err1\",\n",
    "                   \"koi_insol_err2\",\"koi_model_snr\",\"koi_tce_plnt_num\",\"koi_steff\",\"koi_steff_err1\",\n",
    "                   \"koi_steff_err2\",\"koi_slogg\",\"koi_slogg_err1\",\"koi_slogg_err2\",\"koi_srad\",\"koi_srad_err1\",\n",
    "                   \"koi_srad_err2\",\"ra\",\"dec\",\"koi_kepmag\"]\n",
    "\n",
    "data = orig_data[features_to_use]\n",
    "data\n",
    "data = pd.DataFrame(orig_data[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis \n",
    "Explore the data to gain insights about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View dimensions of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 9564 instances and 41 attributes in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe basic statistics of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View summary of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 40 numerical variables and 1 categorical variable in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore problems within variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing values in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values\n",
    "\n",
    "The OEC data has various missing values. Pre-process the data to impute some of the missing values, or handle them you can use the SimpleImputer now.\n",
    "Note: Further investigation may be needed, and different methods could be considered.\n",
    "Any imputation done on the training stage should be consistent with the test stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the target variable\n",
    "\n",
    "Assuming your target variable is 'koi_disposition' and it is stored in a variable called 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check frequency distribution of target variable/class (koi_disposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many examples are in each category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the target variable contains 3 class labels: FALSE POSITIVE, CONFIRMED, CANDIDATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualise the target variable distribution using sns.countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've noticed that the target variable is imbalanced, so we'll need to address this issue later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Transform the set of labels from strings to a suitable encoding such that they can be used with a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset has various categorical columns, consider how you can handle categorical values by generating an alternative encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data from numpy array to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(data)\n",
    "data.columns=[features_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Correlation Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into separate training and test set \n",
    "\n",
    "Split data into separate training and test set using the data and labels you have crafted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable 'label' is imbalanced, meaning some classes have significantly fewer instances than others. To address this imbalance, we're employing SMOTE (Synthetic Minority Over-sampling Technique), a method that creates synthetic samples for the minority classes to achieve a more balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have the opportunity to visualize the distribution of the target variable both before and after the balancing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 1: k-NN\n",
    "\n",
    "### 1- For balanced data\n",
    "Train a k Nearest Neighbours classifier on your dataset, when k=3\n",
    "\n",
    "Hint: from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 1 Model Evaluation:\n",
    "Once you have trained your classifier on the balanced training set, you can evaluate its performance on a test set using various metrics such as confusion matrix, accuracy, precision, and recall. Now evaluate your trined model with variouse metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the accuracy, precision, and recall of the classifier: here, y_test are the true class labels and y_pred are the predicted class labels in the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can compare the train-set and test-set accuracy to check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the scores on training and test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interprete the outcome here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set score (0.8865): This indicates the accuracy or performance of the model on the data it was trained on. A score of 0.8345 suggests that the model performs well on the training data, achieving approximately 88.65% accuracy.\n",
    "\n",
    "Test set score (0.5813): This represents the accuracy or performance of the model on new, unseen data (the test set). A score of 0.5813 suggests that the model's performance drops when applied to data it hasn't seen before, achieving approximately 58.13% accuracy.\n",
    "\n",
    "A significant difference between the training and test set scores might indicate overfitting, where the model is too tailored to the training data and doesn't generalize well to new data. Further model evaluation and tuning may be needed to improve test set performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can use cross-validation to find the best value of k (number of neighbors) for your k-NN classifier.\n",
    "\n",
    "Hint: Find the mean accuracy for different values of k using 5-fold cross-validation. You can then choose the value of k that gives the highest mean accuracy.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interprete your findings here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis indicates that, among the odd values of k tested, the model achieved its highest mean accuracy with k set to 1. The mean accuracy of 0.82 suggests that, on average, the model correctly predicted the class labels for approximately 82% of the instances in the cross-validated training data. This finding implies that a lower k value, in this case, 1, led to better performance on the given training data. It's crucial to note that the choice of the optimal k depends on the specific characteristics of the data, and in this instance, a lower k appears to be favorable for the model's accuracy. Further exploration and consideration of the model's generalization to unseen data may provide additional insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- For unbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can use cross-validation to find the best value of k (number of neighbors) for your k-NN classifier for the unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the classification report for the best value of k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can compare the train-set and test-set accuracy for the unbalanced dataset to check for overfitting. Do you see any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the scores on training and test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier 2: SVC\n",
    "\n",
    "Train a SVC classifier on your dataset with default hyperparameters\n",
    "\n",
    "Default hyperparameter means C=1.0, kernel=rbf and gamma=auto among other parameters.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html#svm\n",
    "\n",
    "Hint: from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier 2 Model Evaluation:\n",
    "Once you have trained your Linear SVC classifier (svc) on the balanced training set, you can evaluate its performance on a test set using various metrics such as confusion matrix, accuracy, precision, and recall. Now evaluate your SVC classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix for all classifiers\n",
    "Draw confusion matrix for all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare performance of classifiers\n",
    "Which classifier performed best over all? Which classifier had the highest accuracy on each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident from the results, the performance of both classifiers is suboptimal. Your next task is to explore alternative analyses with varied parameters for each classifier, experiment with different feature selection techniques, and assess the models using the original unbalanced data. Keep in mind that balancing the data doesn't always guarantee improved performance, so it's crucial to thoroughly investigate various configurations to improve the classifiers' effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing SVM Classifier\n",
    "\n",
    "   - Use the SVM classifier (SVC) from scikit-learn.\n",
    "   - Perform a grid search for hyperparameter optimization using GridSearchCV (cv=3).\n",
    "   - Use the following hyperparameter combinations:\n",
    "       - Kernel: 'linear', 'rbf'\n",
    "       - C: 1.0, 10.0, 100.0\n",
    "       - Gamma: 'scale'\n",
    "   - Use a balanced training dataset (X_train_balanced, y_train_balanced).\n",
    "   - Print the best hyperparameters found by the grid search.\n",
    "   - Print a classification report for the predictions on the test set.\n",
    "   \n",
    "**This task may take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
